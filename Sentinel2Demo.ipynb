{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentinel2Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3798a9e5c31d46b6ac6d1bd3b103f4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_78f655852d004f0fb86572594b409a97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "demo_data/results/seg_maps/example-lombardia/2",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4ba399d80b34d9eb21d8efb995a06e8"
          }
        },
        "78f655852d004f0fb86572594b409a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4ba399d80b34d9eb21d8efb995a06e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "612aa6c26ae647dca9106b34b36e699b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_options_labels": [
              "2-ch5-b0-daily-pred.tif",
              "2-ch38-b0-daily-pred.tif",
              "2-ch20-b0-daily-pred.tif",
              "2-ch62-b0-daily-pred.tif",
              "2-ch67-b0-daily-pred.tif",
              "2-ch4-b0-daily-pred.tif",
              "2-ch68-b0-daily-pred.tif",
              "2-ch9-b0-daily-pred.tif",
              "2-ch26-b0-daily-pred.tif",
              "2-ch39-b0-daily-pred.tif",
              "2-ch58-b0-daily-pred.tif",
              "2-ch52-b0-daily-pred.tif",
              "2-ch2-b0-daily-pred.tif",
              "2-ch21-b0-daily-pred.tif",
              "2-ch24-b0-daily-pred.tif",
              "2-ch57-b0-daily-pred.tif",
              "2-ch53-b0-daily-pred.tif",
              "2-ch51-b0-daily-pred.tif",
              "2-ch45-b0-daily-pred.tif",
              "2-ch36-b0-daily-pred.tif",
              "2-ch32-b0-daily-pred.tif",
              "2-ch27-b0-daily-pred.tif",
              "2-ch54-b0-daily-pred.tif",
              "2-ch40-b0-daily-pred.tif",
              "2-ch61-b0-daily-pred.tif",
              "2-ch34-b0-daily-pred.tif",
              "2-ch50-b0-daily-pred.tif",
              "2-ch3-b0-daily-pred.tif",
              "2-ch6-b0-daily-pred.tif",
              "2-ch49-b0-daily-pred.tif",
              "2-ch63-b0-daily-pred.tif",
              "2-ch33-b0-daily-pred.tif",
              "2-ch46-b0-daily-pred.tif",
              "2-ch0-b0-daily-pred.tif",
              "2-ch11-b0-daily-pred.tif",
              "2-ch8-b0-daily-pred.tif",
              "2-ch22-b0-daily-pred.tif",
              "2-ch41-b0-daily-pred.tif",
              "patch-pred-nn.tif",
              "2-ch28-b0-daily-pred.tif",
              "2-ch55-b0-daily-pred.tif",
              "2-ch69-b0-daily-pred.tif",
              "2-ch17-b0-daily-pred.tif",
              "2-ch31-b0-daily-pred.tif",
              "2-ch23-b0-daily-pred.tif",
              "2-ch47-b0-daily-pred.tif",
              "2-ch37-b0-daily-pred.tif",
              "2-ch12-b0-daily-pred.tif",
              "2-ch19-b0-daily-pred.tif",
              "2-ch25-b0-daily-pred.tif",
              "2-ch15-b0-daily-pred.tif",
              "2-ch29-b0-daily-pred.tif",
              "2-ch42-b0-daily-pred.tif",
              "2-ch35-b0-daily-pred.tif",
              "2-ch18-b0-daily-pred.tif",
              "2-ch70-b0-daily-pred.tif",
              "2-ch60-b0-daily-pred.tif",
              "2-ch65-b0-daily-pred.tif",
              "2-ch13-b0-daily-pred.tif",
              "2-ch7-b0-daily-pred.tif",
              "2-ch1-b0-daily-pred.tif",
              "2-ch16-b0-daily-pred.tif",
              "2-ch14-b0-daily-pred.tif",
              "2-ch56-b0-daily-pred.tif",
              "2-ch44-b0-daily-pred.tif",
              "2-ch64-b0-daily-pred.tif",
              "2-ch43-b0-daily-pred.tif",
              "2-ch10-b0-daily-pred.tif",
              "2-ch59-b0-daily-pred.tif",
              "2-ch66-b0-daily-pred.tif",
              "2-ch48-b0-daily-pred.tif",
              "2-ch30-b0-daily-pred.tif"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_b17921d045d540e3807dbf5445a21880",
            "_dom_classes": [],
            "description": "",
            "_model_name": "DropdownModel",
            "index": 23,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3664b65cf7b94214a00120411ddd8bdc"
          }
        },
        "b17921d045d540e3807dbf5445a21880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3664b65cf7b94214a00120411ddd8bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9e0098696ae4318a88e244afb33cb5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_fafcf1b7af0a45f1b0b03bfbf7a67566",
            "_dom_classes": [],
            "description": "Process",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_d4b5abbe573d43a08ac88ac36d6e5ac8",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "fafcf1b7af0a45f1b0b03bfbf7a67566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4b5abbe573d43a08ac88ac36d6e5ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14046af5c18246c681ca03344e73c5c7": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "demo_data/results/seg_maps/example-lombardia/2/2-ch40-b0-daily-pred.tif\n"
                ]
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_90c75197daf44b9bb4e54dcdbbbea8df",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "90c75197daf44b9bb4e54dcdbbbea8df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8mQ8YNDZ2H4"
      },
      "source": [
        "# Sentinel2 Demo\n",
        "This notebook is used for..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpMi7InfaA8J",
        "cellView": "form",
        "outputId": "4b6925b9-bb2b-4437-d9b6-1a26d4690a3a"
      },
      "source": [
        "#@title Requirements & import\n",
        "\n",
        "!pip install rasterio\n",
        "# !pip install torch\n",
        "\n",
        "\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from functools import partial\n",
        "\n",
        "import numpy\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.2.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.6)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "prjQlkDbaCpr"
      },
      "source": [
        "#@title Dataset Code\n",
        "def print_stats(stats):\n",
        "    print_lst = list()\n",
        "    for k, v in zip(stats.keys(), stats.values()):\n",
        "        print_lst.append(\"{}:{}\".format(k, v))\n",
        "    print('\\n', \", \".join(print_lst))\n",
        "\n",
        "\n",
        "def get_dates(path, n=None):\n",
        "    \"\"\"\n",
        "    extracts a list of unique dates from dataset sample\n",
        "\n",
        "    :param path: to dataset sample folder\n",
        "    :param n: choose n random samples from all available dates\n",
        "    :return: list of unique dates in YYYYMMDD format\n",
        "    \"\"\"\n",
        "\n",
        "    files = os.listdir(path)\n",
        "    dates = list()\n",
        "    for f in files:\n",
        "        f = f.split(\"-\")[0]\n",
        "        if len(f) == 8:  # 20160101\n",
        "            dates.append(f)\n",
        "\n",
        "    dates = set(dates)\n",
        "\n",
        "    if n is not None:\n",
        "        dates = random.sample(dates, n)\n",
        "\n",
        "    dates = list(dates)\n",
        "    dates.sort()\n",
        "    return dates\n",
        "\n",
        "\n",
        "def get_all_dates(path, num_max_dates):\n",
        "    \"\"\"\n",
        "    extracts a list of unique dates from dataset sample\n",
        "\n",
        "    :param path: to dataset sample folder\n",
        "    :param num_max_dates: choose num_max_dates random samples from all available dates\n",
        "    :return: list of unique dates in YYYYMMDD format\n",
        "    \"\"\"\n",
        "    files = os.listdir(path)\n",
        "    dates = list()\n",
        "    for f in files:\n",
        "        f = f.split(\"_\")[0]\n",
        "        if len(f) == 8:  # 20160101\n",
        "            dates.append(f)\n",
        "\n",
        "    dates = set(dates)\n",
        "    if num_max_dates < len(dates):\n",
        "        dates = random.sample(dates, num_max_dates)\n",
        "    dates = list(dates)\n",
        "    dates.sort()\n",
        "    return dates\n",
        "\n",
        "\n",
        "def get_sliding_window(pos, x_annual_time_series, win_size):\n",
        "    # x_annual_time_series to sliding window\n",
        "    sw_stop = pos + 1\n",
        "    sw_start = sw_stop - win_size\n",
        "    if sw_start < 0:\n",
        "        # batch, channels, time_series, H, W = x_annual_time_series.shape\n",
        "        channels, time_series, H, W = x_annual_time_series.shape\n",
        "        # x_win = torch.zeros(batch, channels, win_size, H, W)\n",
        "        x_win = torch.zeros(channels, win_size, H, W)\n",
        "        # x_win[:, :, -sw_stop:, :, :] = x_annual_time_series[:, :, :sw_stop, :, :]\n",
        "        x_win[:, -sw_stop:, :, :] = x_annual_time_series[:, :sw_stop, :, :]\n",
        "    else:\n",
        "        # x_annual[batch, channels, time_series, H, W]\n",
        "        # x_win = x_annual_time_series[:, :, sw_start:sw_stop, :, :]\n",
        "        x_win = x_annual_time_series[:, sw_start:sw_stop, :, :]\n",
        "    return x_win\n",
        "\n",
        "\n",
        "def read_classes(csv):\n",
        "    with open(csv, 'r') as f:\n",
        "        classes = f.readlines()\n",
        "\n",
        "    ids = list()\n",
        "    names = list()\n",
        "    reliable_start_grow = list()\n",
        "    reliable_end_grow = list()\n",
        "    unreliable_start_grow = list()\n",
        "    unreliable_end_grow = list()\n",
        "    for row in classes:\n",
        "        row = row.replace(\"\\n\", \"\")\n",
        "        if '|' in row:\n",
        "            cls_info = row.split('|')\n",
        "            # we can have multiple id\n",
        "            id_info = cls_info[0].split(',')\n",
        "            id_info = [int(x) for x in id_info]\n",
        "            # ids.append(int(cls_info[0]))\n",
        "            ids.append(id_info)\n",
        "            names.append(cls_info[1])\n",
        "            if len(cls_info) > 2:\n",
        "                reliable_start_grow.append(cls_info[2])\n",
        "                reliable_end_grow.append(cls_info[3])\n",
        "            if len(cls_info) > 4:\n",
        "                unreliable_start_grow.append(cls_info[2])\n",
        "                unreliable_end_grow.append(cls_info[3])\n",
        "\n",
        "    return ids, names, reliable_start_grow, reliable_end_grow, \\\n",
        "           unreliable_start_grow, unreliable_end_grow\n",
        "\n",
        "\n",
        "def get_patch_id(samples, idx_img):\n",
        "    _path = samples[idx_img]\n",
        "    if _path.endswith(os.sep):\n",
        "        _path = _path[:-1]\n",
        "    _id = os.path.basename(_path)\n",
        "    return _id, _path\n",
        "\n",
        "\n",
        "class SentinelDailyAnnualDatasetNoLabel(torch.utils.data.Dataset):\n",
        "    '''\n",
        "    If the first label is for example \"1|unknown\" then this will be replaced with a 0 (zero).\n",
        "    If you want to ignore other labels, then remove them from the classes.txt file and\n",
        "    this class will assigne label 0 (zero).\n",
        "    '''\n",
        "\n",
        "    def __init__(self, root_dirs, years, classes_path, max_seq_length, win_size, tileids=None):\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.win_size = win_size\n",
        "        # labels read from groudtruth files (y.tif)\n",
        "        # useful field to check the available labels\n",
        "        self.unique_labels = np.array([], dtype=float)\n",
        "        self.reliable_start_grow = list()\n",
        "        self.reliable_stop_grow = list()\n",
        "        self.unreliable_start_grow = list()\n",
        "        self.unreliable_stop_grow = list()\n",
        "        cls_info = read_classes(classes_path)\n",
        "        self.classids = cls_info[0]\n",
        "        self.classes = cls_info[1]\n",
        "        if len(cls_info[2]) > 0:\n",
        "            self.reliable_start_grow = cls_info[2]\n",
        "            self.reliable_stop_grow = cls_info[3]\n",
        "        if len(cls_info[4]) > 0:\n",
        "            self.unreliable_start_grow = cls_info[4]\n",
        "            self.unreliable_stop_grow = cls_info[5]\n",
        "\n",
        "        if type(years) is not list:\n",
        "            years = [years]\n",
        "        self.data_dirs = years\n",
        "\n",
        "        if type(root_dirs) is not list:\n",
        "            root_dirs = [root_dirs]\n",
        "        self.root_dirs = [r.rstrip(\"/\") for r in root_dirs]\n",
        "        self.name = \"\"\n",
        "        self.samples = list()\n",
        "        self.ndates = list()\n",
        "        for root_dir in self.root_dirs:\n",
        "            print(\"Reading dataset info:\", root_dir)\n",
        "            self.name += os.path.basename(root_dir) + '_'\n",
        "\n",
        "            for d in self.data_dirs:\n",
        "                if not os.path.isdir(os.path.join(root_dir, d)):\n",
        "                    sys.exit('The directory ' + os.path.join(root_dir, d) + \" does not exist!\")\n",
        "\n",
        "            stats = dict(\n",
        "                rejected_nopath=0,\n",
        "                rejected_length=0,\n",
        "                total_samples=0)\n",
        "\n",
        "            dirs = []\n",
        "            if tileids is None:\n",
        "                # files = os.listdir(self.data_dirs)\n",
        "                for d in self.data_dirs:\n",
        "                    dirs_name = os.listdir(os.path.join(root_dir, d))\n",
        "                    dirs_path = [os.path.join(root_dir, d, f) for f in dirs_name]\n",
        "                    dirs.extend(dirs_path)\n",
        "            else:\n",
        "                # tileids e.g. \"tileids/train_fold0.tileids\" path of line separated tileids specifying\n",
        "                with open(os.path.join(root_dir, tileids), 'r') as f:\n",
        "                    files = [el.replace(\"\\n\", \"\") for el in f.readlines()]\n",
        "                for d in self.data_dirs:\n",
        "                    dirs_path = [os.path.join(root_dir, d, f) for f in files]\n",
        "                    dirs.extend(dirs_path)\n",
        "\n",
        "            for path in dirs:\n",
        "                if not os.path.exists(path):\n",
        "                    stats[\"rejected_nopath\"] += 1\n",
        "                    continue\n",
        "                ndates = len(get_dates(path))\n",
        "\n",
        "                stats[\"total_samples\"] += 1\n",
        "                self.samples.append(path)\n",
        "                self.ndates.append(ndates)\n",
        "\n",
        "            print_stats(stats)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx_img):\n",
        "        patch_id, path = get_patch_id(self.samples, idx_img)\n",
        "\n",
        "        dates = get_all_dates(path, self.max_seq_length)\n",
        "\n",
        "        x_annual = list()\n",
        "\n",
        "        for date in dates:\n",
        "            x10_img, profile = read(os.path.join(path, date + \".tif\"))\n",
        "            x_annual.append(x10_img)\n",
        "\n",
        "        padding_size = max(0, self.max_seq_length - len(dates))\n",
        "        for i in range(padding_size):\n",
        "            # y_dailies.append(np.zeros_like(y_dailies[0]))\n",
        "            x_annual.append(np.zeros_like(x_annual[0]))\n",
        "            dates.append(dates[-1][:4] + '1231')\n",
        "        # dates = np.pad(dates, (0, padding_size - 1), mode='edge')  # padding with mirror\n",
        "\n",
        "        x_annual = np.array(x_annual) * 1e-4\n",
        "        x_annual = torch.from_numpy(x_annual)\n",
        "\n",
        "        # permute channels with time_series (t x c x h x w) -> (c x t x h x w)\n",
        "        x_annual = x_annual.permute(1, 0, 2, 3)\n",
        "\n",
        "        x_annual = x_annual.float()\n",
        "\n",
        "        # create sliding windows from x_annual\n",
        "        x_dailies = list()\n",
        "        for i in range(len(dates)):\n",
        "            x_win = get_sliding_window(i, x_annual, self.win_size)\n",
        "            x_dailies.append(x_win)\n",
        "        x_dailies = torch.stack(x_dailies)\n",
        "\n",
        "        # return x_dailies, y_annual, y_dailies, dates, patch_id\n",
        "        return x_dailies, dates, path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHR5ZHVSaL_4"
      },
      "source": [
        "Models Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "QXPIVlyraLWr"
      },
      "source": [
        "#@title Models code\n",
        "\n",
        "# annual model\n",
        "class SimpleNN(nn.Module):\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.num_classes = opt.n_classes\n",
        "        self.conv1 = nn.Conv3d(\n",
        "            opt.sample_duration,\n",
        "            # opt.sample_channels,\n",
        "            64,\n",
        "            kernel_size=(7, 3, 3),  # orig: 7\n",
        "            stride=(1, 1, 1),  # orig: (1, 2, 2)\n",
        "            padding=(3, 1, 1),  # orig: (3, 3, 3)\n",
        "            bias=False)\n",
        "        self.conv2 = nn.Conv3d(\n",
        "            64,\n",
        "            128,\n",
        "            # kernel_size=(opt.sample_channels-opt.n_classes+1, 3, 3),  # orig: 7\n",
        "            kernel_size=(3, 3, 3),  # orig: 7\n",
        "            stride=(1, 1, 1),  # orig: (1, 2, 2)\n",
        "            padding=(1, 1, 1),  # orig: (3, 3, 3)\n",
        "            bias=False)\n",
        "        self.conv3 = nn.Conv3d(\n",
        "            128,\n",
        "            1,\n",
        "            # kernel_size=(opt.sample_channels-opt.n_classes+1, 3, 3),  # orig: 7\n",
        "            kernel_size=(3, 3, 3),  # orig: 7\n",
        "            stride=(1, 1, 1),  # orig: (1, 2, 2)\n",
        "            padding=(1, 1, 1),  # orig: (3, 3, 3)\n",
        "            bias=False)\n",
        "\n",
        "    @staticmethod\n",
        "    def upsample3d(x, d, h, w):\n",
        "        return F.interpolate(x, size=(d, h, w), mode='trilinear', align_corners=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, _, h, w = x.shape\n",
        "        out = torch.relu(self.conv1(x))\n",
        "        out = self.upsample3d(out, self.num_classes, h, w)\n",
        "        out = torch.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        out = out.squeeze(1)\n",
        "        return out, out\n",
        "\n",
        "\n",
        "# daily\n",
        "def get_fine_tuning_parameters(model, ft_begin_index):\n",
        "    if ft_begin_index == 0:\n",
        "        return model.parameters()\n",
        "\n",
        "    ft_module_names = []\n",
        "    for i in range(ft_begin_index, 5):\n",
        "        ft_module_names.append('layer{}'.format(i))\n",
        "    ft_module_names.append('fc')\n",
        "\n",
        "    parameters = []\n",
        "    for k, v in model.named_parameters():\n",
        "        for ft_module in ft_module_names:\n",
        "            if ft_module in k:\n",
        "                parameters.append({'params': v})\n",
        "                break\n",
        "        else:\n",
        "            parameters.append({'params': v, 'lr': 0.0})\n",
        "\n",
        "    return parameters\n",
        "\n",
        "\n",
        "def downsample_basic_block(x, planes, stride):\n",
        "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
        "    zero_pads = torch.Tensor(\n",
        "        out.size(0), planes - out.size(1), out.size(2), out.size(3),\n",
        "        out.size(4)).zero_()\n",
        "    if isinstance(out.data, torch.cuda.FloatTensor):\n",
        "        zero_pads = zero_pads.cuda()\n",
        "\n",
        "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.conv2 = nn.Conv3d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 block,\n",
        "                 layers,\n",
        "                 opt,\n",
        "                 # sample_size,  # Height and width of inputs es. 112 x 112\n",
        "                 sample_duration,  # Temporal duration of inputs, es. 16\n",
        "                 # shortcut_type='B',\n",
        "                 # num_classes=400\n",
        "                 ):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        kernel0 = min(7, sample_duration)\n",
        "        padding0 = int(kernel0 / 2)\n",
        "        self.conv1 = nn.Conv3d(\n",
        "            # opt.sample_duration,\n",
        "            opt.sample_channels,\n",
        "            64,\n",
        "            kernel_size=(kernel0, 3, 3),  # orig: 7\n",
        "            stride=(1, 1, 1),  # orig: (1, 2, 2)\n",
        "            padding=(padding0, 1, 1),  # orig: (3, 3, 3)\n",
        "            bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], opt.resnet_shortcut)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], opt.resnet_shortcut, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], opt.resnet_shortcut, stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], opt.resnet_shortcut, stride=2)\n",
        "        # last_duration = int(math.ceil(sample_duration / 16))\n",
        "        # last_size = int(math.ceil(sample_size / 32))\n",
        "        # self.avgpool = nn.AvgPool3d(\n",
        "        #     (last_duration, last_size, last_size), stride=1)\n",
        "        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                m.weight = nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            if shortcut_type == 'A':\n",
        "                downsample = partial(\n",
        "                    downsample_basic_block,\n",
        "                    planes=planes * block.expansion,\n",
        "                    stride=stride)\n",
        "            else:\n",
        "                downsample = nn.Sequential(\n",
        "                    nn.Conv3d(\n",
        "                        self.inplanes,\n",
        "                        planes * block.expansion,\n",
        "                        kernel_size=1,\n",
        "                        stride=stride,\n",
        "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        low_level_feat1 = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        low_level_feat2 = x\n",
        "        x = self.layer2(x)\n",
        "        low_level_feat3 = x\n",
        "        x = self.layer3(x)\n",
        "        low_level_feat4 = x\n",
        "        x = self.layer4(x)\n",
        "        low_level_feat5 = x\n",
        "        return [low_level_feat1, low_level_feat2, low_level_feat3, low_level_feat4, low_level_feat5]\n",
        "\n",
        "        # x = self.avgpool(x)\n",
        "\n",
        "        # x = x.view(x.size(0), -1)\n",
        "        # x = self.fc(x)\n",
        "\n",
        "        # return x\n",
        "\n",
        "\n",
        "def resnet50(opt, sample_duration):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], opt, sample_duration)\n",
        "    return model\n",
        "\n",
        "\n",
        "class FPN(nn.Module):\n",
        "\n",
        "    def __init__(self, opt, first_batch, sample_duration):\n",
        "        super(FPN, self).__init__()\n",
        "        # self.first_run = True\n",
        "        self.in_planes = 64\n",
        "        self.num_classes = opt.n_classes\n",
        "\n",
        "        model = resnet50(opt, sample_duration)\n",
        "        self.back_bone = nn.DataParallel(model, device_ids=None)\n",
        "        # if opt.pretrain_path:\n",
        "        #     print('loading pretrained model {}'.format(opt.pretrain_path))\n",
        "        #     pretrain = torch.load(opt.pretrain_path)\n",
        "        #     assert opt.arch == pretrain['arch']\n",
        "        #\n",
        "        #     model.load_state_dict(pretrain['state_dict'])\n",
        "        #\n",
        "        #     if opt.model == 'densenet':\n",
        "        #         model.module.classifier = nn.Linear(\n",
        "        #             model.module.classifier.in_features, opt.n_finetune_classes)\n",
        "        #         model.module.classifier = model.module.classifier.cuda()\n",
        "        #     else:\n",
        "        #         model.module.fc = nn.Linear(model.module.fc.in_features,\n",
        "        #                                     opt.n_finetune_classes)\n",
        "        #         model.module.fc = model.module.fc.cuda()\n",
        "        #\n",
        "        #     parameters = get_fine_tuning_parameters(model, opt.ft_begin_index)\n",
        "\n",
        "        # self.back_bone, parameters = generate_model(opt, sample_duration)\n",
        "\n",
        "        # Top layer\n",
        "        self.toplayer = None  # nn.Conv3d(512, 256, kernel_size=1, stride=1, padding=0)  # Reduce channels\n",
        "\n",
        "        # Lateral layers\n",
        "        self.latlayer1 = None  # nn.Conv3d(256, 256, kernel_size=1, stride=1, padding=0\n",
        "        self.latlayer2 = None  # nn.Conv3d(128, 256, kernel_size=1, stride=1, padding=0)\n",
        "        self.latlayer3 = None  # nn.Conv3d(64, 256, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        # Addendum layers to reduce channels before sum\n",
        "        self.sumlayer1 = None\n",
        "        self.sumlayer2 = None\n",
        "        self.sumlayer3 = None\n",
        "\n",
        "        # Semantic branch\n",
        "        self.conv2_3d_p5 = None\n",
        "        self.conv2_3d_p4 = None\n",
        "        self.conv2_3d_p3 = None\n",
        "        self.conv2_3d_p2 = None\n",
        "        self.iam_joking(first_batch, not opt.no_cuda)\n",
        "\n",
        "        self.semantic_branch_2d = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2_2d = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        # self.conv3 = nn.Conv2d(128, self.num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0)\n",
        "        # opt.sample_duration is the number of samples taken from the time series\n",
        "        self.conv4out = nn.Conv2d(64, opt.sample_duration, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5out = nn.Conv2d(opt.sample_duration, self.num_classes, kernel_size=3, stride=1, padding=1)\n",
        "        # num_groups, num_channels\n",
        "        self.gn1 = nn.GroupNorm(128, 128)\n",
        "        self.gn2 = nn.GroupNorm(256, 256)\n",
        "\n",
        "    def iam_joking(self, x, use_cuda):\n",
        "        low_level_features = self.back_bone(x)\n",
        "        c1 = low_level_features[0]\n",
        "        c2 = low_level_features[1]\n",
        "        c3 = low_level_features[2]\n",
        "        c4 = low_level_features[3]\n",
        "        c5 = low_level_features[4]\n",
        "\n",
        "        # Top layer\n",
        "        self.toplayer = nn.Conv3d(c5.size()[1], c5.size()[1], kernel_size=1, stride=1, padding=0)  # Reduce channels\n",
        "        # Lateral layers\n",
        "        self.latlayer1 = nn.Conv3d(c4.size()[1], c4.size()[1], kernel_size=1, stride=1, padding=0)\n",
        "        self.latlayer2 = nn.Conv3d(c3.size()[1], c3.size()[1], kernel_size=1, stride=1, padding=0)\n",
        "        self.latlayer3 = nn.Conv3d(c2.size()[1], c2.size()[1], kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        # Addendum layers to reduce channels\n",
        "        self.sumlayer1 = nn.Conv3d(c5.size()[1], c4.size()[1], kernel_size=1, stride=1, padding=0)  # Reduce channels\n",
        "        self.sumlayer2 = nn.Conv3d(c4.size()[1], c3.size()[1], kernel_size=1, stride=1, padding=0)\n",
        "        self.sumlayer3 = nn.Conv3d(c3.size()[1], c2.size()[1], kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if use_cuda:\n",
        "            self.toplayer = self.toplayer.cuda()\n",
        "            self.latlayer1 = self.latlayer1.cuda()\n",
        "            self.latlayer2 = self.latlayer2.cuda()\n",
        "            self.latlayer3 = self.latlayer3.cuda()\n",
        "            self.sumlayer1 = self.sumlayer1.cuda()\n",
        "            self.sumlayer2 = self.sumlayer2.cuda()\n",
        "            self.sumlayer3 = self.sumlayer3.cuda()\n",
        "\n",
        "        # Top-down\n",
        "        p5 = self.toplayer(c5)\n",
        "        p4 = self._upsample_add(self.sumlayer1(p5), self.latlayer1(c4))\n",
        "        p3 = self._upsample_add(self.sumlayer2(p4), self.latlayer2(c3))\n",
        "        p2 = self._upsample_add(self.sumlayer3(p3), self.latlayer3(c2))\n",
        "\n",
        "        # calculate the sizes so that dimension c becomes 1\n",
        "        self.conv2_3d_p5 = nn.Conv3d(p5.size()[1], 256, kernel_size=(p5.size()[2] + 2, 3, 3), stride=1, padding=1)\n",
        "        self.conv2_3d_p4 = nn.Conv3d(p4.size()[1], 256, kernel_size=(p4.size()[2] + 2, 3, 3), stride=1, padding=1)\n",
        "        self.conv2_3d_p3 = nn.Conv3d(p3.size()[1], 128, kernel_size=(p3.size()[2] + 2, 3, 3), stride=1, padding=1)\n",
        "        self.conv2_3d_p2 = nn.Conv3d(p2.size()[1], 128, kernel_size=(p2.size()[2] + 2, 3, 3), stride=1, padding=1)\n",
        "\n",
        "    def _upsample3d(self, x, d, h, w):\n",
        "        return F.interpolate(x, size=(d, h, w), mode='trilinear', align_corners=True)\n",
        "\n",
        "    def _upsample2d(self, x, h, w):\n",
        "        return F.interpolate(x, size=(h, w), mode='bilinear', align_corners=True)\n",
        "\n",
        "    def _make_layer(self, Bottleneck, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(Bottleneck(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * Bottleneck.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _upsample_add(self, x, y):\n",
        "        '''Upsample and add two feature maps.\n",
        "        Args:\n",
        "          x: (Variable) top feature map to be upsampled.\n",
        "          y: (Variable) lateral feature map.\n",
        "        Returns:\n",
        "          (Variable) added feature map.\n",
        "        Note in PyTorch, when input size is odd, the upsampled feature map\n",
        "        with `F.upsample(..., scale_factor=2, mode='nearest')`\n",
        "        maybe not equal to the lateral feature map size.\n",
        "        e.g.\n",
        "        original input size: [N,_,15,15] ->\n",
        "        conv2d feature map size: [N,_,8,8] ->\n",
        "        upsampled feature map size: [N,_,16,16]\n",
        "        So we choose bilinear upsample which supports arbitrary output sizes.\n",
        "        '''\n",
        "        _, _, D, H, W = y.size()\n",
        "        return F.interpolate(x, size=(D, H, W), mode='trilinear', align_corners=True) + y\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Bottom-up using backbone\n",
        "        low_level_features = self.back_bone(x)\n",
        "        # c1 = low_level_features[0]\n",
        "        c2 = low_level_features[1]\n",
        "        c3 = low_level_features[2]\n",
        "        c4 = low_level_features[3]\n",
        "        c5 = low_level_features[4]\n",
        "\n",
        "        # Top-down\n",
        "        p5 = self.toplayer(c5)\n",
        "        p4 = self._upsample_add(\n",
        "            torch.relu(self.sumlayer1(p5)), torch.relu(self.latlayer1(c4)))  # p5 interpolation to the size of c4\n",
        "        p3 = self._upsample_add(\n",
        "            torch.relu(self.sumlayer2(p4)), torch.relu(self.latlayer2(c3)))\n",
        "        p2 = self._upsample_add(\n",
        "            torch.relu(self.sumlayer3(p3)), torch.relu(self.latlayer3(c2)))\n",
        "\n",
        "        # Smooth\n",
        "        # p4 = F.relu(self.smooth1(p4))\n",
        "        # p3 = F.relu(self.smooth2(p3))\n",
        "        # p2 = F.relu(self.smooth3(p2))\n",
        "\n",
        "        # Semantic\n",
        "        _, _, _, h, w = p2.size()\n",
        "        # 256->256\n",
        "        s5 = self.conv2_3d_p5(p5)\n",
        "        s5 = torch.squeeze(s5, 2)  # squeeze only dim 2 to avoid to remove the batch dimension\n",
        "        s5 = self._upsample2d(torch.relu(self.gn2(s5)), h, w)\n",
        "        # 256->256 [32, 256, 24, 24]\n",
        "        s5 = self._upsample2d(torch.relu(self.gn2(self.conv2_2d(s5))), h, w)\n",
        "        # 256->128 [32, 128, 24, 24]\n",
        "        s5 = self._upsample2d(torch.relu(self.gn1(self.semantic_branch_2d(s5))), h, w)\n",
        "\n",
        "        # 256->256 p4:[32, 256, 4, 6, 6] -> s4:[32, 256, 1, 6, 6]\n",
        "        s4 = self.conv2_3d_p4(p4)\n",
        "        s4 = torch.squeeze(s4, 2)  # s4:[32, 256, 6, 6]\n",
        "        s4 = self._upsample2d(torch.relu(self.gn2(s4)), h, w)  # s4:[32, 256, 24, 24]\n",
        "        # 256->128  s4:[32, 128, 24, 24]\n",
        "        s4 = self._upsample2d(torch.relu(self.gn1(self.semantic_branch_2d(s4))), h, w)\n",
        "\n",
        "        # 256->128\n",
        "        s3 = self.conv2_3d_p3(p3)\n",
        "        s3 = torch.squeeze(s3, 2)\n",
        "        s3 = self._upsample2d(torch.relu(self.gn1(s3)), h, w)\n",
        "\n",
        "        s2 = self.conv2_3d_p2(p2)\n",
        "        s2 = torch.squeeze(s2, 2)\n",
        "        s2 = self._upsample2d(torch.relu(self.gn1(s2)), h, w)\n",
        "\n",
        "        out = self._upsample2d(self.conv3(s2 + s3 + s4 + s5), 2 * h, 2 * w)\n",
        "        # introducing MSELoss on NDVI signal\n",
        "        out_cai = torch.sigmoid(self.conv4out(out))  # for Class Activation Interval\n",
        "        out_cls = self.conv5out(out_cai)  # for Classification\n",
        "\n",
        "        return out_cai, out_cls\n",
        "\n",
        "\n",
        "def ids_to_labels(dataloader, pred_labels):\n",
        "    new = np.zeros(pred_labels.shape, np.int)\n",
        "    for cl, i in zip(dataloader.dataset.classids, range(len(dataloader.dataset.classids))):\n",
        "        if type(cl) is list:\n",
        "            new[pred_labels == i] = cl[0]\n",
        "            # for c in cl:\n",
        "            #     new[pred_labels == c] = i\n",
        "        else:\n",
        "            new[pred_labels == i] = cl\n",
        "    return new\n",
        "\n",
        "\n",
        "def resume(path, model, optimizer):\n",
        "    if torch.cuda.is_available():\n",
        "        snapshot = torch.load(path)\n",
        "    else:\n",
        "        snapshot = torch.load(path, map_location=\"cpu\")\n",
        "    print(\"Loaded snapshot from\", path)\n",
        "\n",
        "    model_state = snapshot.pop('model_state', snapshot)\n",
        "    optimizer_state = snapshot.pop('optimizer_state', None)\n",
        "\n",
        "    if model is not None and model_state is not None:\n",
        "        print(\"loading model...\")\n",
        "        model.load_state_dict(model_state)\n",
        "\n",
        "    if optimizer is not None and optimizer_state is not None:\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "    return snapshot\n",
        "\n",
        "\n",
        "def read(file):\n",
        "    with rasterio.open(file) as src:\n",
        "        return src.read(), src.profile"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdJhX8G4aTXz"
      },
      "source": [
        "Paramiters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Z6tDfbRhaSye"
      },
      "source": [
        "#@title Setup Parameters\n",
        "\n",
        "opt = type('test', (), {})()\n",
        "\n",
        "opt.gpu_id = ''\n",
        "opt.no_cuda = True\n",
        "\n",
        "opt.n_classes = 8\n",
        "opt.model_depth = 50\n",
        "opt.batch_size = 1\n",
        "opt.sample_duration = 71\n",
        "opt.sample_channels = 9\n",
        "opt.win_size = 5\n",
        "opt.model = 'resnet'\n",
        "opt.resnet_shortcut = 'B'\n",
        "# opt.n_epochs = 20\n",
        "# opt.learning_rate = 0.01\n",
        "# opt.loss = 'ce'\n",
        "# opt.optimizer = 'sgd'\n",
        "# opt.export_only\n",
        "# opt.test_tile = 'test_small.tileids'\n",
        "opt.result_path = 'demo_data/results'\n",
        "opt.root_path = ['demo_data/lombardia']\n",
        "opt.years = ['example']\n",
        "opt.classes_path = 'demo_data/classes-newmapping.txt'\n",
        "opt.resume_path = 'demo_data'\n",
        "opt.pretrain_path = ''\n",
        "opt.workers = 1\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_id\n",
        "if opt.no_cuda:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDZe-F6CaZrT"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "mm-4mj6Kffx2",
        "outputId": "35e01266-a394-4e25-fb05-1329b15c1404"
      },
      "source": [
        "#@title Download model weights and sample data\n",
        "! rm demo_data.zip\n",
        "! rm -rf demo_data\n",
        "! wget link https://github.com/nicolalandro/empty/releases/download/0.1/demo_data.zip\n",
        "! unzip demo_data.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'demo_data.zip': No such file or directory\n",
            "--2021-12-09 16:21:01--  http://link/\n",
            "Resolving link (link)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‘link’\n",
            "--2021-12-09 16:21:01--  https://github.com/nicolalandro/empty/releases/download/0.1/demo_data.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/434605507/6618d0ee-4ab3-4328-8243-848b7fd561c3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211209T162102Z&X-Amz-Expires=300&X-Amz-Signature=858a8648da4303182e490aa5f9711d19a92b955020d9c3208c7dd460620e732f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=434605507&response-content-disposition=attachment%3B%20filename%3Ddemo_data.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-09 16:21:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/434605507/6618d0ee-4ab3-4328-8243-848b7fd561c3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211209T162102Z&X-Amz-Expires=300&X-Amz-Signature=858a8648da4303182e490aa5f9711d19a92b955020d9c3208c7dd460620e732f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=434605507&response-content-disposition=attachment%3B%20filename%3Ddemo_data.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914515842 (872M) [application/octet-stream]\n",
            "Saving to: ‘demo_data.zip’\n",
            "\n",
            "demo_data.zip       100%[===================>] 872.15M  18.1MB/s    in 46s     \n",
            "\n",
            "2021-12-09 16:21:48 (18.8 MB/s) - ‘demo_data.zip’ saved [914515842/914515842]\n",
            "\n",
            "FINISHED --2021-12-09 16:21:48--\n",
            "Total wall clock time: 47s\n",
            "Downloaded: 1 files, 872M in 46s (18.8 MB/s)\n",
            "Archive:  demo_data.zip\n",
            "   creating: demo_data/\n",
            "  inflating: demo_data/best_model_daily.pth  \n",
            "  inflating: demo_data/best_model_annual.pth  \n",
            "  inflating: demo_data/classes-newmapping.txt  \n",
            "   creating: demo_data/lombardia/\n",
            "   creating: demo_data/lombardia/example/\n",
            "   creating: demo_data/lombardia/example/2/\n",
            "  inflating: demo_data/lombardia/example/2/20191016.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191011.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191006.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191001.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190926.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190921.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190916.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190911.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190906.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190901.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190827.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190822.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190817.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190812.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190807.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190802.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190728.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190723.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190718.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190713.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190708.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191230_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191225_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190703.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191220_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191215_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190628.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191210_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191205_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190623.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191130_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191120_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190618.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191115_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191110_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190613.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191105_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191031_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190603.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191026_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191021_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190529.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191016_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191011_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190524.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191006_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191001_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190519.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190926_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190921_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190514.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190916_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190911_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190509.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190906_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190901_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190504.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190827_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190822_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190429.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190817_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190812_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190424.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190807_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190802_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190419.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190728_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190723_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190414.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190718_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190713_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190409.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190708_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190703_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190404.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190628_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190623_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190330.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190618_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190613_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190325.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190603_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190529_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190320.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190524_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190519_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190315.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190514_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190509_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190310.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190504_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190429_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190305.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190424_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190419_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190228.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190414_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190409_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190223.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190404_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190330_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190218.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190325_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190320_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190213.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190315_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190310_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190208.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190305_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190228_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190203.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190223_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190218_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190129.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190213_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190208_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190203_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190124.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190129_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190124_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190119.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190119_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190114_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190114.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190109_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190104_MSAVI.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190109.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20190104.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191230.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191225.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191220.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191215.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191210.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191205.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191130.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191120.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191115.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191110.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191105.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191031.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191026.tif  \n",
            "  inflating: demo_data/lombardia/example/2/20191021.tif  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "a4AsUdpGaZGs",
        "outputId": "bab97716-d4a2-4a42-b8ff-6656a1693828"
      },
      "source": [
        "#@title Load pretrained weights\n",
        "\n",
        "best_model_daily_file_name = \"best_model_daily.pth\"\n",
        "best_model_annual_file_name = \"best_model_annual.pth\"\n",
        "\n",
        "first_input_batch = torch.zeros(71, 9, 5, 48, 48)\n",
        "# first_input_batch = first_input_batch.view(-1, *first_input_batch.shape[2:])\n",
        "daily_model = FPN(opt, first_input_batch, opt.win_size)\n",
        "annual_model = SimpleNN(opt)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    daily_model = torch.nn.DataParallel(daily_model).cuda()\n",
        "    annual_model = torch.nn.DataParallel(annual_model).cuda()\n",
        "    daily_model = torch.nn.DataParallel(daily_model).cuda()\n",
        "    annual_model = torch.nn.DataParallel(annual_model).cuda()\n",
        "else:\n",
        "    daily_model = torch.nn.DataParallel(daily_model).cpu()\n",
        "    annual_model = torch.nn.DataParallel(annual_model).cpu()\n",
        "    daily_model = torch.nn.DataParallel(daily_model).cpu()\n",
        "    annual_model = torch.nn.DataParallel(annual_model).cpu()\n",
        "\n",
        "print('trying to resume previous saved models...')\n",
        "state = resume(\n",
        "    os.path.join(opt.resume_path, best_model_daily_file_name),\n",
        "    model=daily_model, optimizer=None)\n",
        "state = resume(\n",
        "    os.path.join(opt.resume_path, best_model_annual_file_name),\n",
        "    model=annual_model, optimizer=None)\n",
        "daily_model = daily_model.eval()\n",
        "annual_model = annual_model.eval()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying to resume previous saved models...\n",
            "Loaded snapshot from demo_data/best_model_daily.pth\n",
            "loading model...\n",
            "Loaded snapshot from demo_data/best_model_annual.pth\n",
            "loading model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELIdUsLlj0gx",
        "cellView": "form",
        "outputId": "f2f441bc-8b53-4f2c-9320-2a75d697873d"
      },
      "source": [
        "#@title Predict from \"demo_data/lombardia/example\" to \"demo_data/results\"\n",
        "\n",
        "validationdataset = SentinelDailyAnnualDatasetNoLabel(\n",
        "    opt.root_path,\n",
        "    opt.years,\n",
        "    opt.classes_path,\n",
        "    opt.sample_duration,\n",
        "    opt.win_size,\n",
        "    tileids=None)\n",
        "validationdataloader = torch.utils.data.DataLoader(\n",
        "    validationdataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.workers)\n",
        "\n",
        "out_dir = os.path.join(opt.result_path, \"seg_maps\")\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "with torch.no_grad():\n",
        "    x_dailies, dates, dirs_path = next(iter(validationdataloader))\n",
        "    # reshape merging the first two dimensions\n",
        "    x_dailies = x_dailies.view(-1, *x_dailies.shape[2:])\n",
        "    if torch.cuda.is_available():\n",
        "        x_dailies = x_dailies.cuda()\n",
        "\n",
        "    feat_daily, outs_daily = daily_model.forward(x_dailies)\n",
        "    # return to original size of batch and year\n",
        "    outs_daily = outs_daily.view(opt.batch_size, opt.sample_duration, *outs_daily.shape[1:])\n",
        "    feat_daily = feat_daily.view(opt.batch_size, opt.sample_duration, *feat_daily.shape[1:])\n",
        "\n",
        "    _, out_annual = annual_model.forward(feat_daily)\n",
        "    pred_annual = torch.argmax(out_annual, dim=1).squeeze(1)\n",
        "    pred_annual = pred_annual.cpu().numpy()\n",
        "    # Remapping the labels\n",
        "    pred_annual_nn = ids_to_labels(validationdataloader, pred_annual).astype(numpy.uint8)\n",
        "\n",
        "    for batch in range(feat_daily.shape[0]):\n",
        "        # _, profile = read(os.path.join(dirs_path[batch], '20191230_MSAVI.tif'))  # todo get the last image\n",
        "        _, tmp_path = get_patch_id(validationdataset.samples, 0)\n",
        "        dates = get_all_dates(tmp_path, validationdataset.max_seq_length)\n",
        "        last_tif_path = os.path.join(tmp_path, dates[-1] + \".tif\")\n",
        "        _, profile = read(last_tif_path)\n",
        "        profile[\"name\"] = dirs_path[batch]\n",
        "\n",
        "        pth = dirs_path[batch].split(os.path.sep)[-3:]\n",
        "        full_pth_patch = os.path.join(out_dir, pth[1] + '-' + pth[0], pth[2])\n",
        "\n",
        "        if not os.path.exists(full_pth_patch):\n",
        "            os.makedirs(full_pth_patch)\n",
        "        full_pth_pred = os.path.join(full_pth_patch, 'patch-pred-nn.tif')\n",
        "        profile.update({\n",
        "            'nodata': None,\n",
        "            'dtype': 'uint8',\n",
        "            'count': 1})\n",
        "        with rasterio.open(full_pth_pred, 'w', **profile) as dst:\n",
        "            dst.write_band(1, pred_annual_nn[batch])\n",
        "\n",
        "        # patch_predictions = None\n",
        "        for ch in range(len(dates)):\n",
        "            soft_seg = outs_daily[batch, ch, :, :, :]\n",
        "            # transform probs into a hard segmentation\n",
        "            pred_daily = torch.argmax(soft_seg, dim=0)\n",
        "            pred_daily = pred_daily.cpu()\n",
        "            daily_pred = ids_to_labels(validationdataloader, pred_daily).astype(numpy.uint8)\n",
        "            # if patch_predictions is None:\n",
        "            #     patch_predictions = numpy.expand_dims(daily_pred, axis=0)\n",
        "            # else:\n",
        "            #     patch_predictions = numpy.concatenate((patch_predictions, numpy.expand_dims(daily_pred, axis=0)),\n",
        "            #                                           axis=0)\n",
        "\n",
        "            # save GT image in  opt.root_path\n",
        "            full_pth_date = os.path.join(full_pth_patch, dates[ch][batch] + f'-ch{ch}-b{batch}-daily-pred.tif')\n",
        "            profile.update({\n",
        "                'nodata': None,\n",
        "                'dtype': 'uint8',\n",
        "                'count': 1})\n",
        "            with rasterio.open(full_pth_date, 'w', **profile) as dst:\n",
        "                dst.write_band(1, daily_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading dataset info: demo_data/lombardia\n",
            "\n",
            " rejected_nopath:0, rejected_length:0, total_samples:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG7kQLMSlDXf",
        "outputId": "94998493-7a69-433c-9097-5f70a2b362be"
      },
      "source": [
        "! ls demo_data/results/seg_maps/example-lombardia/2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-ch0-b0-daily-pred.tif   2-ch31-b0-daily-pred.tif  2-ch53-b0-daily-pred.tif\n",
            "2-ch10-b0-daily-pred.tif  2-ch32-b0-daily-pred.tif  2-ch54-b0-daily-pred.tif\n",
            "2-ch11-b0-daily-pred.tif  2-ch33-b0-daily-pred.tif  2-ch55-b0-daily-pred.tif\n",
            "2-ch12-b0-daily-pred.tif  2-ch34-b0-daily-pred.tif  2-ch56-b0-daily-pred.tif\n",
            "2-ch13-b0-daily-pred.tif  2-ch35-b0-daily-pred.tif  2-ch57-b0-daily-pred.tif\n",
            "2-ch14-b0-daily-pred.tif  2-ch36-b0-daily-pred.tif  2-ch58-b0-daily-pred.tif\n",
            "2-ch15-b0-daily-pred.tif  2-ch37-b0-daily-pred.tif  2-ch59-b0-daily-pred.tif\n",
            "2-ch16-b0-daily-pred.tif  2-ch38-b0-daily-pred.tif  2-ch5-b0-daily-pred.tif\n",
            "2-ch17-b0-daily-pred.tif  2-ch39-b0-daily-pred.tif  2-ch60-b0-daily-pred.tif\n",
            "2-ch18-b0-daily-pred.tif  2-ch3-b0-daily-pred.tif   2-ch61-b0-daily-pred.tif\n",
            "2-ch19-b0-daily-pred.tif  2-ch40-b0-daily-pred.tif  2-ch62-b0-daily-pred.tif\n",
            "2-ch1-b0-daily-pred.tif   2-ch41-b0-daily-pred.tif  2-ch63-b0-daily-pred.tif\n",
            "2-ch20-b0-daily-pred.tif  2-ch42-b0-daily-pred.tif  2-ch64-b0-daily-pred.tif\n",
            "2-ch21-b0-daily-pred.tif  2-ch43-b0-daily-pred.tif  2-ch65-b0-daily-pred.tif\n",
            "2-ch22-b0-daily-pred.tif  2-ch44-b0-daily-pred.tif  2-ch66-b0-daily-pred.tif\n",
            "2-ch23-b0-daily-pred.tif  2-ch45-b0-daily-pred.tif  2-ch67-b0-daily-pred.tif\n",
            "2-ch24-b0-daily-pred.tif  2-ch46-b0-daily-pred.tif  2-ch68-b0-daily-pred.tif\n",
            "2-ch25-b0-daily-pred.tif  2-ch47-b0-daily-pred.tif  2-ch69-b0-daily-pred.tif\n",
            "2-ch26-b0-daily-pred.tif  2-ch48-b0-daily-pred.tif  2-ch6-b0-daily-pred.tif\n",
            "2-ch27-b0-daily-pred.tif  2-ch49-b0-daily-pred.tif  2-ch70-b0-daily-pred.tif\n",
            "2-ch28-b0-daily-pred.tif  2-ch4-b0-daily-pred.tif   2-ch7-b0-daily-pred.tif\n",
            "2-ch29-b0-daily-pred.tif  2-ch50-b0-daily-pred.tif  2-ch8-b0-daily-pred.tif\n",
            "2-ch2-b0-daily-pred.tif   2-ch51-b0-daily-pred.tif  2-ch9-b0-daily-pred.tif\n",
            "2-ch30-b0-daily-pred.tif  2-ch52-b0-daily-pred.tif  patch-pred-nn.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cCXwvhX8oB9I",
        "outputId": "28bfe382-1728-4385-9f6a-f24740285900"
      },
      "source": [
        "#@title Zip and Download \"demo_data/results\"\n",
        "\n",
        "from google.colab import files\n",
        "!zip -r results.zip demo_data/results\n",
        "files.download('results.zip')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: demo_data/results/ (stored 0%)\n",
            "  adding: demo_data/results/seg_maps/ (stored 0%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/ (stored 0%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/ (stored 0%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch36-b0-daily-pred.tif (deflated 36%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch14-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch7-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch51-b0-daily-pred.tif (deflated 46%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch42-b0-daily-pred.tif (deflated 32%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch26-b0-daily-pred.tif (deflated 37%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch12-b0-daily-pred.tif (deflated 45%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch45-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch67-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch18-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch69-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch46-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch13-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch27-b0-daily-pred.tif (deflated 39%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/patch-pred-nn.tif (deflated 24%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch8-b0-daily-pred.tif (deflated 45%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch16-b0-daily-pred.tif (deflated 43%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch22-b0-daily-pred.tif (deflated 32%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch21-b0-daily-pred.tif (deflated 38%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch52-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch40-b0-daily-pred.tif (deflated 40%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch20-b0-daily-pred.tif (deflated 45%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch28-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch24-b0-daily-pred.tif (deflated 45%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch19-b0-daily-pred.tif (deflated 41%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch44-b0-daily-pred.tif (deflated 39%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch9-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch10-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch4-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch65-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch39-b0-daily-pred.tif (deflated 33%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch37-b0-daily-pred.tif (deflated 34%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch53-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch33-b0-daily-pred.tif (deflated 41%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch48-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch64-b0-daily-pred.tif (deflated 45%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch11-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch1-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch6-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch23-b0-daily-pred.tif (deflated 37%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch57-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch41-b0-daily-pred.tif (deflated 32%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch5-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch59-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch38-b0-daily-pred.tif (deflated 35%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch32-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch0-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch43-b0-daily-pred.tif (deflated 43%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch35-b0-daily-pred.tif (deflated 34%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch56-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch29-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch34-b0-daily-pred.tif (deflated 36%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch25-b0-daily-pred.tif (deflated 39%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch54-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch63-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch61-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch31-b0-daily-pred.tif (deflated 31%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch30-b0-daily-pred.tif (deflated 39%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch3-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch2-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch70-b0-daily-pred.tif (deflated 43%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch49-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch15-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch58-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch55-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch66-b0-daily-pred.tif (deflated 45%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch68-b0-daily-pred.tif (deflated 46%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch50-b0-daily-pred.tif (deflated 46%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch47-b0-daily-pred.tif (deflated 46%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch60-b0-daily-pred.tif (deflated 47%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch17-b0-daily-pred.tif (deflated 44%)\n",
            "  adding: demo_data/results/seg_maps/example-lombardia/2/2-ch62-b0-daily-pred.tif (deflated 47%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5f2da117-671b-4585-a547-d985e92aa1dd\", \"results.zip\", 38184)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNGA62INf8nR"
      },
      "source": [
        "# Visual representations\n",
        "TODO, use matplot to analize the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tsFEP0FgCOEx"
      },
      "source": [
        "#@title Requirements & import for plot\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes_color_map = np.array([[0., 0., 0.],                          # Black\n",
        "                              [0.79215686, 1.00000000, 0.43921569],  # DarkGreen\n",
        "                              [0.78039216, 0.08235294, 0.52156863],  # MediumVioletRed\n",
        "                              [0.00000000, 0.39215686, 0.00000000],  # DarkOliveGreen1\n",
        "                              [0, 0, 1],                             # Blue\n",
        "                              [1.00000000, 0.84313725, 0.00000000],  # gold\n",
        "                              [0.62745098, 0.12549020, 0.94117647],  # purple\n",
        "                              [0.0, 100/255, 0.0],                   # DarkGreen\n",
        "                              [0.98039216, 0.66666667, 0.62745098],  #\n",
        "                              [1, 1, 0],                             # yellow\n",
        "                              [0.2745098, 0.2745098, 0.2745098],     #\n",
        "                              [0, 250/255, 154/255],                 # MediumSpringGreen\n",
        "                              [64/255, 224/255, 208/255],            # turquoise\n",
        "                              [0.70588235, 0.64705882, 0.70588235],  #\n",
        "                              [0.58823529, 0.39215686, 0.39215686],  #\n",
        "                              [139/255, 35/255, 35/255],             # brown4\n",
        "                              [0.6, 0.6, 0.6],\n",
        "                              [0.98039216, 0.66666667, 0.11764706],\n",
        "                              [0.8627451, 0.8627451, 0.],\n",
        "                              [0.41960784, 0.55686275, 0.1372549],\n",
        "                              [0.2745098, 0.50980392, 0.70588235],\n",
        "                              [0.8627451, 0.07843137, 0.23529412],\n",
        "                              [1., 0., 0.],\n",
        "                              [0., 0., 0.55686275],\n",
        "                              [0., 0., 0.2745098],\n",
        "                              [0., 0.23529412, 0.39215686],\n",
        "                              [0., 0., 0.35294118],\n",
        "                              [0., 0., 0.43137255],\n",
        "                              [0., 0.31372549, 0.39215686],\n",
        "                              [0., 0., 0.90196078],\n",
        "                              [0.46666667, 0.04313725, 0.1254902],\n",
        "                              [0., 0., 0.55686275]])\n",
        "colors = classes_color_map[:8] # num classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoKQk6IngGql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878,
          "referenced_widgets": [
            "3798a9e5c31d46b6ac6d1bd3b103f4d0",
            "78f655852d004f0fb86572594b409a97",
            "c4ba399d80b34d9eb21d8efb995a06e8",
            "612aa6c26ae647dca9106b34b36e699b",
            "b17921d045d540e3807dbf5445a21880",
            "3664b65cf7b94214a00120411ddd8bdc",
            "f9e0098696ae4318a88e244afb33cb5b",
            "fafcf1b7af0a45f1b0b03bfbf7a67566",
            "d4b5abbe573d43a08ac88ac36d6e5ac8",
            "14046af5c18246c681ca03344e73c5c7",
            "90c75197daf44b9bb4e54dcdbbbea8df"
          ]
        },
        "cellView": "form",
        "outputId": "edb09425-abb1-4130-9c3f-f72ea00a8e8c"
      },
      "source": [
        "#@title Print Image Tool\n",
        "\n",
        "folder = \"demo_data/results/seg_maps/example-lombardia/2\"\n",
        "paths = os.listdir(folder)\n",
        "folder_path = widgets.Text(folder)\n",
        "file_picker = widgets.Dropdown(options=paths, value=\"patch-pred-nn.tif\")\n",
        "\n",
        "button = widgets.Button(description=\"Process\")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "  with output:\n",
        "    clear_output()\n",
        "    file_path = os.path.join(folder_path.value, file_picker.value)\n",
        "    print(file_path)\n",
        "    target, profile = read(file_path)\n",
        "    target = np.squeeze(target)\n",
        "    target = [classes_color_map[p] for p in target]\n",
        "    plt.imshow(target)\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "display(folder_path,file_picker, button, output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3798a9e5c31d46b6ac6d1bd3b103f4d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='demo_data/results/seg_maps/example-lombardia/2')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "612aa6c26ae647dca9106b34b36e699b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(index=38, options=('2-ch5-b0-daily-pred.tif', '2-ch38-b0-daily-pred.tif', '2-ch20-b0-daily-pred.tif',…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9e0098696ae4318a88e244afb33cb5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Button(description='Process', style=ButtonStyle())"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14046af5c18246c681ca03344e73c5c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}